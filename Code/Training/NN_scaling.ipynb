{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_scaling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "JNepJEYE45-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "3fb66f55-380a-4696-8ad6-4b9998992b87"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import numpy as np\n",
        "# import modin.pandas as pd\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.feature_selection import RFE, f_regression\n",
        "\n",
        "import itertools\n",
        "\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "sns.set_style({'font.sans-serif': ['simsun', 'Arial']})\n",
        "sns.set_style('darkgrid', {'font.sans-serif': ['simhei', 'Arial']})\n",
        "%matplotlib inline\n",
        "\n",
        "# np.random.seed(4590)\n",
        "data_path = r'./train_data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df.head(5)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>企业编号</th>\n",
              "      <th>企业总评分</th>\n",
              "      <th>软著数量</th>\n",
              "      <th>作品著作数量</th>\n",
              "      <th>项目数量</th>\n",
              "      <th>纳税A级年份_2014</th>\n",
              "      <th>纳税A级年份_2015</th>\n",
              "      <th>纳税A级年份_2016</th>\n",
              "      <th>纳税A级年份_2017</th>\n",
              "      <th>资质证书数量</th>\n",
              "      <th>...</th>\n",
              "      <th>应收账款周转天数(天)_mean</th>\n",
              "      <th>应收账款周转天数(天)_max</th>\n",
              "      <th>应收账款周转天数(天)_min</th>\n",
              "      <th>应收账款周转天数(天)_std</th>\n",
              "      <th>应收账款周转天数(天)滚动增长_mean</th>\n",
              "      <th>存货周转天数(天)_mean</th>\n",
              "      <th>存货周转天数(天)_max</th>\n",
              "      <th>存货周转天数(天)_min</th>\n",
              "      <th>存货周转天数(天)_std</th>\n",
              "      <th>存货周转天数(天)滚动增长_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>75.374276</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>107.589270</td>\n",
              "      <td>191.707773</td>\n",
              "      <td>63.791689</td>\n",
              "      <td>44.495607</td>\n",
              "      <td>0.151392</td>\n",
              "      <td>414.778035</td>\n",
              "      <td>1089.655763</td>\n",
              "      <td>176.283983</td>\n",
              "      <td>325.371499</td>\n",
              "      <td>1.562757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>79.830122</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>46.903333</td>\n",
              "      <td>56.590000</td>\n",
              "      <td>39.830000</td>\n",
              "      <td>6.234116</td>\n",
              "      <td>0.023916</td>\n",
              "      <td>6.506667</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>5.010000</td>\n",
              "      <td>0.702335</td>\n",
              "      <td>0.045330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>78.318264</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>...</td>\n",
              "      <td>84.275556</td>\n",
              "      <td>139.910000</td>\n",
              "      <td>56.020000</td>\n",
              "      <td>33.143654</td>\n",
              "      <td>-0.040224</td>\n",
              "      <td>54.918889</td>\n",
              "      <td>75.540000</td>\n",
              "      <td>38.010000</td>\n",
              "      <td>11.089465</td>\n",
              "      <td>0.031792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004</td>\n",
              "      <td>83.253376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.720000</td>\n",
              "      <td>35.360000</td>\n",
              "      <td>17.290000</td>\n",
              "      <td>6.024438</td>\n",
              "      <td>0.081857</td>\n",
              "      <td>6.954444</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>6.240000</td>\n",
              "      <td>0.618448</td>\n",
              "      <td>0.021711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1005</td>\n",
              "      <td>83.291493</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>94.050000</td>\n",
              "      <td>110.260000</td>\n",
              "      <td>77.850000</td>\n",
              "      <td>9.652235</td>\n",
              "      <td>0.012921</td>\n",
              "      <td>108.584444</td>\n",
              "      <td>357.190000</td>\n",
              "      <td>44.160000</td>\n",
              "      <td>101.728838</td>\n",
              "      <td>0.344086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 308 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   企业编号      企业总评分  软著数量  作品著作数量  项目数量  纳税A级年份_2014  纳税A级年份_2015  纳税A级年份_2016  \\\n",
              "0  1001  75.374276   1.0     1.0   1.0          1.0          2.0          1.0   \n",
              "1  1002  79.830122   2.0     0.0   1.0          1.0          1.0          2.0   \n",
              "2  1003  78.318264   2.0     0.0   1.0          1.0          1.0          0.0   \n",
              "3  1004  83.253376   0.0     6.0   1.0          0.0          0.0          2.0   \n",
              "4  1005  83.291493   6.0     0.0   1.0          0.0          0.0          0.0   \n",
              "\n",
              "   纳税A级年份_2017  资质证书数量         ...          应收账款周转天数(天)_mean  应收账款周转天数(天)_max  \\\n",
              "0          1.0     9.0         ...                107.589270       191.707773   \n",
              "1          0.0     0.0         ...                 46.903333        56.590000   \n",
              "2          1.0   442.0         ...                 84.275556       139.910000   \n",
              "3          1.0     1.0         ...                 26.720000        35.360000   \n",
              "4          0.0     5.0         ...                 94.050000       110.260000   \n",
              "\n",
              "   应收账款周转天数(天)_min  应收账款周转天数(天)_std  应收账款周转天数(天)滚动增长_mean  存货周转天数(天)_mean  \\\n",
              "0        63.791689        44.495607              0.151392      414.778035   \n",
              "1        39.830000         6.234116              0.023916        6.506667   \n",
              "2        56.020000        33.143654             -0.040224       54.918889   \n",
              "3        17.290000         6.024438              0.081857        6.954444   \n",
              "4        77.850000         9.652235              0.012921      108.584444   \n",
              "\n",
              "   存货周转天数(天)_max  存货周转天数(天)_min  存货周转天数(天)_std  存货周转天数(天)滚动增长_mean  \n",
              "0    1089.655763     176.283983     325.371499            1.562757  \n",
              "1       7.040000       5.010000       0.702335            0.045330  \n",
              "2      75.540000      38.010000      11.089465            0.031792  \n",
              "3       7.900000       6.240000       0.618448            0.021711  \n",
              "4     357.190000      44.160000     101.728838            0.344086  \n",
              "\n",
              "[5 rows x 308 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "_qVvxGsx5ORV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79fc62f1-f80d-4a44-f181-22c186e6b50e"
      },
      "cell_type": "code",
      "source": [
        "y = df[['企业编号', '企业总评分']]\n",
        "x = df.drop(['企业总评分'], axis=1)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=31)\n",
        "ytrain_id = ytrain['企业编号']\n",
        "ytrain = ytrain['企业总评分']\n",
        "ytest_id = ytest['企业编号']\n",
        "ytest = ytest['企业总评分']\n",
        "print(xtrain.shape, xtest.shape, ytrain.shape, ytest.shape)\n",
        "\n",
        "id_train = xtrain['企业编号']\n",
        "id_test = xtest['企业编号']\n",
        "xtrain.drop(['企业编号'], axis=1, inplace=True)\n",
        "xtest.drop(['企业编号'], axis=1, inplace=True)\n",
        "feature_name=xtrain.columns.values"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2364, 307) (592, 307) (2364,) (592,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HfjOXg6KAE39",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nfolds = 10\n",
        "folds = KFold(n_splits=nfolds, shuffle=True, random_state=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gY1TN1QMBX_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # objective and metric\n",
        "    \"objective\": \"regression\",\n",
        "    \"metric\": 'rmse',\n",
        "    \"boosting\": \"gbdt\",\n",
        "\n",
        "    # for the Leaf-wise (Best-first) Tree\n",
        "    \"num_leaves\": 100, \n",
        "    # smaller than 2^(max_depth), This is the main parameter to control the complexity of the tree model. With larger can get higher accuracy \n",
        "    \"min_data_in_leaf\": 20, # Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.\n",
        "    \"max_depth\": 7, # limit the tree depth explicitly.\n",
        "\n",
        "    # For Faster Speed\n",
        "    \"bagging_fraction\": 0.7,\n",
        "    \"bagging_freq\": 1,\n",
        "#     \"max_bin\": 5, # more small more faster\n",
        "    \"bagging_seed\": 11,\n",
        "\n",
        "    # For Better Accuracy\n",
        "    \"max_bin\": 20, # lager but slower\n",
        "    \"learning_rate\": 0.005,\n",
        "\n",
        "    # deal with over fitting\n",
        "      # Use small max_bin\n",
        "      # Use small num_leaves\n",
        "      # Use min_data_in_leaf and min_sum_hessian_in_leaf\n",
        "      # Use bagging by set bagging_fraction and bagging_freq\n",
        "      # Use feature sub-sampling by set feature_fraction\n",
        "      # Use bigger training data\n",
        "      # Try lambda_l1, lambda_l2 and min_gain_to_split for regularization\n",
        "      # Try max_depth to avoid growing deep tree\n",
        "    \"feature_fraction\": 0.8,\n",
        "    \"lambda_l1\": 0.1,\n",
        "\n",
        "    \"min_child_samples\": 100,\n",
        "\n",
        "    # other\n",
        "    \"n_estimators\": 1500,\n",
        "    \"verbosity\": -1,\n",
        "    \"n_jobs\":-1,\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dM_VJVGBp52",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_lgbm(xtrain, ytrain, xtest, ytest, params):\n",
        "    feature_importance_df = np.zeros((xtrain.shape[1], nfolds))\n",
        "    mvalid = np.zeros(len(xtrain))\n",
        "    mfull = np.zeros(len(xtest))\n",
        "    models = []\n",
        "\n",
        "\n",
        "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(xtrain.values, ytrain.values)):\n",
        "        print('----')\n",
        "        print(\"fold n°{}\".format(fold_))\n",
        "\n",
        "        x0, y0 = xtrain.iloc[trn_idx], ytrain.iloc[trn_idx]\n",
        "        x1, y1 = xtrain.iloc[val_idx], ytrain.iloc[val_idx]\n",
        "\n",
        "        trn_data = lgb.Dataset(x0, label=y0)\n",
        "        val_data = lgb.Dataset(x1, label=y1)\n",
        "\n",
        "        num_round = 10000\n",
        "        clf = lgb.train(params,\n",
        "                        trn_data,\n",
        "                        num_round,\n",
        "                        valid_sets=[trn_data, val_data],\n",
        "                        verbose_eval=500,\n",
        "                        early_stopping_rounds=150)\n",
        "\n",
        "        mvalid[val_idx] = clf.predict(x1, num_iteration=clf.best_iteration)\n",
        "\n",
        "        feature_importance_df[:, fold_] = clf.feature_importance()\n",
        "\n",
        "        mfull += clf.predict(xtest,\n",
        "                             num_iteration=clf.best_iteration) / folds.n_splits\n",
        "        \n",
        "        models.append(clf)\n",
        "\n",
        "\n",
        "    test_error=np.sqrt(mean_squared_error(mfull.astype(int), ytest.astype(int)))\n",
        "    print()\n",
        "    print('rmse:', test_error)\n",
        "    return models, test_error, feature_importance_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oVPBU8ZxECkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1173
        },
        "outputId": "2a5b9de9-0a27-41ee-e7cb-8c84d3b31ab9"
      },
      "cell_type": "code",
      "source": [
        "models, test_error, feature_importance_df=train_lgbm(xtrain, ytrain, xtest, ytest, params)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "fold n°0\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.22361\tvalid_1's rmse: 3.51007\n",
            "[1000]\ttraining's rmse: 1.64857\tvalid_1's rmse: 3.46088\n",
            "[1500]\ttraining's rmse: 1.27279\tvalid_1's rmse: 3.44803\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1500]\ttraining's rmse: 1.27279\tvalid_1's rmse: 3.44803\n",
            "----\n",
            "fold n°1\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.27432\tvalid_1's rmse: 2.90939\n",
            "Early stopping, best iteration is:\n",
            "[806]\ttraining's rmse: 1.86382\tvalid_1's rmse: 2.86939\n",
            "----\n",
            "fold n°2\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.27339\tvalid_1's rmse: 3.2435\n",
            "[1000]\ttraining's rmse: 1.67923\tvalid_1's rmse: 3.20472\n",
            "Early stopping, best iteration is:\n",
            "[861]\ttraining's rmse: 1.81384\tvalid_1's rmse: 3.20347\n",
            "----\n",
            "fold n°3\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.28578\tvalid_1's rmse: 3.10941\n",
            "Early stopping, best iteration is:\n",
            "[788]\ttraining's rmse: 1.91104\tvalid_1's rmse: 3.05653\n",
            "----\n",
            "fold n°4\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.27913\tvalid_1's rmse: 2.85378\n",
            "[1000]\ttraining's rmse: 1.67697\tvalid_1's rmse: 2.77035\n",
            "Early stopping, best iteration is:\n",
            "[1013]\ttraining's rmse: 1.66443\tvalid_1's rmse: 2.76918\n",
            "----\n",
            "fold n°5\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.2618\tvalid_1's rmse: 3.07016\n",
            "Early stopping, best iteration is:\n",
            "[798]\ttraining's rmse: 1.87355\tvalid_1's rmse: 3.02174\n",
            "----\n",
            "fold n°6\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.25358\tvalid_1's rmse: 3.22999\n",
            "[1000]\ttraining's rmse: 1.67066\tvalid_1's rmse: 3.12908\n",
            "Early stopping, best iteration is:\n",
            "[1147]\ttraining's rmse: 1.55137\tvalid_1's rmse: 3.12321\n",
            "----\n",
            "fold n°7\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.25208\tvalid_1's rmse: 3.33271\n",
            "Early stopping, best iteration is:\n",
            "[832]\ttraining's rmse: 1.83159\tvalid_1's rmse: 3.27141\n",
            "----\n",
            "fold n°8\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.26901\tvalid_1's rmse: 3.0803\n",
            "Early stopping, best iteration is:\n",
            "[820]\ttraining's rmse: 1.85204\tvalid_1's rmse: 3.03318\n",
            "----\n",
            "fold n°9\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.27128\tvalid_1's rmse: 3.18035\n",
            "[1000]\ttraining's rmse: 1.67466\tvalid_1's rmse: 3.12215\n",
            "Early stopping, best iteration is:\n",
            "[850]\ttraining's rmse: 1.81852\tvalid_1's rmse: 3.11812\n",
            "\n",
            "rmse: 3.112474899497183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LJK5OQIQCWCm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scalling"
      ]
    },
    {
      "metadata": {
        "id": "RUQhPbnVBuo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sc_X = StandardScaler()\n",
        "xtrain_sc = sc_X.fit_transform(xtrain)\n",
        "xtest_sc = sc_X.transform(xtest)\n",
        "xtrain_sc=pd.DataFrame(xtrain_sc)\n",
        "xtest_sc=pd.DataFrame(xtest_sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "optL4xMuKkcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sc_Y = StandardScaler()\n",
        "ytrain_sc = ytrain.values.reshape(-1, 1)\n",
        "ytest_sc = ytest.values.reshape(-1, 1)\n",
        "ytrain_sc = sc_Y.fit_transform(ytrain_sc)\n",
        "# ytrain_sc\n",
        "ytest_sc = sc_Y.transform(ytest_sc)\n",
        "ytrain_sc=pd.DataFrame(ytrain_sc)\n",
        "ytest_sc=pd.DataFrame(ytest_sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9DSUUxuD4N4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1139
        },
        "outputId": "97b43a75-f7db-42f1-a725-45d6c17bdb21"
      },
      "cell_type": "code",
      "source": [
        "feature_importance_df = np.zeros((xtrain.shape[1], nfolds))\n",
        "mvalid = np.zeros(len(xtrain))\n",
        "mfull = np.zeros(len(xtest))\n",
        "\n",
        "\n",
        "for fold_, (trn_idx, val_idx) in enumerate(folds.split(xtrain_sc.values, ytrain.values)):\n",
        "    print('----')\n",
        "    print(\"fold n°{}\".format(fold_))\n",
        "\n",
        "    x0, y0 = xtrain_sc.iloc[trn_idx], ytrain.iloc[trn_idx]\n",
        "    x1, y1 = xtrain_sc.iloc[val_idx], ytrain.iloc[val_idx]\n",
        "\n",
        "    trn_data = lgb.Dataset(x0, label=y0)\n",
        "    val_data = lgb.Dataset(x1, label=y1)\n",
        "\n",
        "    num_round = 10000\n",
        "    clf = lgb.train(params,\n",
        "                    trn_data,\n",
        "                    num_round,\n",
        "                    valid_sets=[trn_data, val_data],\n",
        "                    verbose_eval=500,\n",
        "                    early_stopping_rounds=150)\n",
        "    \n",
        "    mvalid[val_idx] = clf.predict(x1, num_iteration=clf.best_iteration)\n",
        "\n",
        "    feature_importance_df[:, fold_] = clf.feature_importance()\n",
        "\n",
        "    mfull += clf.predict(xtest_sc,\n",
        "                         num_iteration=clf.best_iteration) / folds.n_splits\n",
        "    \n",
        "    \n",
        "np.sqrt(mean_squared_error(mfull.astype(int), ytest.astype(int)))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "fold n°0\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.22266\tvalid_1's rmse: 3.52962\n",
            "[1000]\ttraining's rmse: 1.64963\tvalid_1's rmse: 3.47491\n",
            "Early stopping, best iteration is:\n",
            "[1150]\ttraining's rmse: 1.52106\tvalid_1's rmse: 3.46925\n",
            "----\n",
            "fold n°1\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.27162\tvalid_1's rmse: 2.91861\n",
            "[1000]\ttraining's rmse: 1.66565\tvalid_1's rmse: 2.87745\n",
            "Early stopping, best iteration is:\n",
            "[850]\ttraining's rmse: 1.81013\tvalid_1's rmse: 2.87358\n",
            "----\n",
            "fold n°2\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.26765\tvalid_1's rmse: 3.25502\n",
            "Early stopping, best iteration is:\n",
            "[797]\ttraining's rmse: 1.87535\tvalid_1's rmse: 3.21849\n",
            "----\n",
            "fold n°3\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.28073\tvalid_1's rmse: 3.09527\n",
            "[1000]\ttraining's rmse: 1.70106\tvalid_1's rmse: 3.05292\n",
            "Early stopping, best iteration is:\n",
            "[949]\ttraining's rmse: 1.74665\tvalid_1's rmse: 3.05053\n",
            "----\n",
            "fold n°4\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.27564\tvalid_1's rmse: 2.84905\n",
            "Early stopping, best iteration is:\n",
            "[821]\ttraining's rmse: 1.85064\tvalid_1's rmse: 2.76966\n",
            "----\n",
            "fold n°5\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.25498\tvalid_1's rmse: 3.0764\n",
            "[1000]\ttraining's rmse: 1.66906\tvalid_1's rmse: 3.02886\n",
            "Early stopping, best iteration is:\n",
            "[924]\ttraining's rmse: 1.74044\tvalid_1's rmse: 3.02832\n",
            "----\n",
            "fold n°6\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.24972\tvalid_1's rmse: 3.23699\n",
            "[1000]\ttraining's rmse: 1.65881\tvalid_1's rmse: 3.13549\n",
            "Early stopping, best iteration is:\n",
            "[1057]\ttraining's rmse: 1.61099\tvalid_1's rmse: 3.13054\n",
            "----\n",
            "fold n°7\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.23976\tvalid_1's rmse: 3.32956\n",
            "Early stopping, best iteration is:\n",
            "[804]\ttraining's rmse: 1.85366\tvalid_1's rmse: 3.27133\n",
            "----\n",
            "fold n°8\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.26907\tvalid_1's rmse: 3.06917\n",
            "Early stopping, best iteration is:\n",
            "[840]\ttraining's rmse: 1.83758\tvalid_1's rmse: 3.02061\n",
            "----\n",
            "fold n°9\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[500]\ttraining's rmse: 2.26715\tvalid_1's rmse: 3.16955\n",
            "Early stopping, best iteration is:\n",
            "[846]\ttraining's rmse: 1.81579\tvalid_1's rmse: 3.11187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1108463261409853"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "-vIG4G1qFKvz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3H-JYjoGGyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xtrain_th=torch.from_numpy(xtrain_sc.values).float()\n",
        "xtest_th=torch.from_numpy(xtest_sc.values).float()\n",
        "\n",
        "\n",
        "# ytrain_sc=ytrain.values.reshape(-1,1)\n",
        "ytrain_th=torch.from_numpy(ytrain_sc.values).float()\n",
        "ytest_th=torch.from_numpy(ytest_sc.values).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIjFjXkEHVai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xtrain_th, ytrain_th = Variable(xtrain_th), Variable(ytrain_th)\n",
        "xtest_th, ytest_th = Variable(xtest_th), Variable(ytest_th)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drQHI0DqH-q-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = torch.nn.Sequential(\n",
        "        torch.nn.Linear(xtrain_th.shape[1], 200),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        torch.nn.Linear(200, 500),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        torch.nn.Linear(500, ytrain_th.shape[1]),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x6VANeBJIDml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BexW1qoRIEFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d7aec01e-c8ab-4404-800e-44a359cae4a8"
      },
      "cell_type": "code",
      "source": [
        "for t in range(2000):\n",
        "  \n",
        "    prediction = net(xtrain_th)     # input x and predict based on x\n",
        "\n",
        "    loss = loss_func(prediction, ytrain_th)     # must be (1. nn output, 2. target)\n",
        "    optimizer.zero_grad()   # clear gradients for next train\n",
        "    loss.backward()         # backpropagation, compute gradients\n",
        "    optimizer.step()\n",
        "    test_prediction = net(xtest_th)\n",
        "    test_loss = loss_func(test_prediction, ytest_th)\n",
        "    if t % 100 ==0:\n",
        "      print('Iter:',t,'Loss:',np.sqrt(test_loss.data.numpy()))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter: 0 Loss: 199.81769\n",
            "Iter: 100 Loss: 1.7156724\n",
            "Iter: 200 Loss: 2.2657738\n",
            "Iter: 300 Loss: 1.9196215\n",
            "Iter: 400 Loss: 1.4814303\n",
            "Iter: 500 Loss: 2.9830425\n",
            "Iter: 600 Loss: 1.7475812\n",
            "Iter: 700 Loss: 1.8111961\n",
            "Iter: 800 Loss: 3.2180133\n",
            "Iter: 900 Loss: 3.6163108\n",
            "Iter: 1000 Loss: 2.964648\n",
            "Iter: 1100 Loss: 3.6365278\n",
            "Iter: 1200 Loss: 3.887578\n",
            "Iter: 1300 Loss: 3.860841\n",
            "Iter: 1400 Loss: 2.571096\n",
            "Iter: 1500 Loss: 2.9154544\n",
            "Iter: 1600 Loss: 3.3825932\n",
            "Iter: 1700 Loss: 2.618896\n",
            "Iter: 1800 Loss: 2.614862\n",
            "Iter: 1900 Loss: 2.6909013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "34LenxGcIplC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}