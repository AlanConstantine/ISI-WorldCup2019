{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First param\n",
    "```\n",
    "params = {'num_leaves': 50,\n",
    "         'min_data_in_leaf': 30,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "```\n",
    "* no scaling with all features rmse: 2.997465145301492\n",
    "* scaling with all features rmse: 3.548410378777547\n",
    "* no scaling with first level features: 3.0118011132785556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:58:43.280329Z",
     "start_time": "2019-04-15T11:58:43.275039Z"
    }
   },
   "source": [
    "## Second param\n",
    "```\n",
    "params = {'num_leaves': 12,\n",
    "          'min_data_in_leaf': 30,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': 6,\n",
    "          'learning_rate': 0.1,\n",
    "          \"min_child_samples\": 100,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.7,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'rmse',\n",
    "          \"lambda_l1\": 0.1,\n",
    "          \"verbosity\": -1,\n",
    "          \"device\":'cpu',\n",
    "          \"n_jobs\":4,\n",
    "          \"n_estimators\":1000}\n",
    "```\n",
    "* no scaling with all features rmse: 3.0274643747764465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'num_leaves': 50,\n",
    "         'min_data_in_leaf': 30,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,}\n",
    "```\n",
    "* no scaling with all features rmse: 3.026627326410203"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'num_leaves': 60,\n",
    "         'min_data_in_leaf': 40,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "```\n",
    "3.0269063682516117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "param = {'num_leaves': 40,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"n_jobs\":8,\n",
    "         \"n_estimators\":941}\n",
    "```\n",
    "3.0380470255955108"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'num_leaves': 70,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 7,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"n_jobs\":8,\n",
    "         \"n_estimators\":941}\n",
    "```\n",
    "2.992106733173585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'num_leaves': 100,\n",
    "         'min_data_in_leaf': 10,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 7,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"n_jobs\":8,\n",
    "         \"n_estimators\":941}\n",
    "```\n",
    "3.0106791906792707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'num_leaves': 80,\n",
    "         'min_data_in_leaf': 10,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 7,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 100,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"n_jobs\":8,\n",
    "         \"n_estimators\":941}\n",
    "```\n",
    "3.0064682521775197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {\n",
    "    # objective and metric\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": 'rmse',\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \n",
    "    # for the Leaf-wise (Best-first) Tree\n",
    "    \"num_leaves\": 100, \n",
    "    # smaller than 2^(max_depth), This is the main parameter to control the complexity of the tree model. With larger can get higher accuracy \n",
    "    \"min_data_in_leaf\": 20, # Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.\n",
    "    \"max_depth\": 7, # limit the tree depth explicitly.\n",
    "    \n",
    "    # For Faster Speed\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    \"bagging_freq\": 1,\n",
    "#     \"max_bin\": 5, # more small more faster\n",
    "    \"bagging_seed\": 11,\n",
    "    \n",
    "    # For Better Accuracy\n",
    "    \"max_bin\": 20, # lager but slower\n",
    "    \"learning_rate\": 0.005,\n",
    "    \n",
    "    # deal with over fitting\n",
    "      # Use small max_bin\n",
    "      # Use small num_leaves\n",
    "      # Use min_data_in_leaf and min_sum_hessian_in_leaf\n",
    "      # Use bagging by set bagging_fraction and bagging_freq\n",
    "      # Use feature sub-sampling by set feature_fraction\n",
    "      # Use bigger training data\n",
    "      # Try lambda_l1, lambda_l2 and min_gain_to_split for regularization\n",
    "      # Try max_depth to avoid growing deep tree\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \n",
    "    \"min_child_samples\": 100,\n",
    "    \n",
    "    # other\n",
    "    \"n_estimators\": 941,\n",
    "    \"verbosity\": -1,\n",
    "    \"n_jobs\":8,\n",
    "}\n",
    "```\n",
    "2.9887175230242873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params = {\n",
    "    # objective and metric\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": 'rmse',\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \n",
    "    # for the Leaf-wise (Best-first) Tree\n",
    "    \"num_leaves\": 100, \n",
    "    # smaller than 2^(max_depth), This is the main parameter to control the complexity of the tree model. With larger can get higher accuracy \n",
    "    \"min_data_in_leaf\": 20, # Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.\n",
    "    \"max_depth\": 7, # limit the tree depth explicitly.\n",
    "    \n",
    "    # For Faster Speed\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    \"bagging_freq\": 1,\n",
    "#     \"max_bin\": 5, # more small more faster\n",
    "    \"bagging_seed\": 11,\n",
    "    \n",
    "    # For Better Accuracy\n",
    "    \"max_bin\": 20, # lager but slower\n",
    "    \"learning_rate\": 0.005,\n",
    "    \n",
    "    # deal with over fitting\n",
    "      # Use small max_bin\n",
    "      # Use small num_leaves\n",
    "      # Use min_data_in_leaf and min_sum_hessian_in_leaf\n",
    "      # Use bagging by set bagging_fraction and bagging_freq\n",
    "      # Use feature sub-sampling by set feature_fraction\n",
    "      # Use bigger training data\n",
    "      # Try lambda_l1, lambda_l2 and min_gain_to_split for regularization\n",
    "      # Try max_depth to avoid growing deep tree\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \n",
    "    \"min_child_samples\": 100,\n",
    "    \n",
    "    # other\n",
    "    \"n_estimators\": 1500,\n",
    "    \"verbosity\": -1,\n",
    "    \"n_jobs\":8,\n",
    "}\n",
    "```\n",
    "2.9540398357759754"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first level\n",
    "```\n",
    "params1 = {\n",
    "    # objective and metric\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": 'rmse',\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \n",
    "    # for the Leaf-wise (Best-first) Tree\n",
    "    \"num_leaves\": 100, \n",
    "    # smaller than 2^(max_depth), This is the main parameter to control the complexity of the tree model. With larger can get higher accuracy \n",
    "    \"min_data_in_leaf\": 20, # Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.\n",
    "    \"max_depth\": 7, # limit the tree depth explicitly.\n",
    "    \n",
    "    # For Faster Speed\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    \"bagging_freq\": 1,\n",
    "#     \"max_bin\": 5, # more small more faster\n",
    "    \"bagging_seed\": 11,\n",
    "    \n",
    "    # For Better Accuracy\n",
    "    \"max_bin\": 20, # lager but slower\n",
    "    \"learning_rate\": 0.005,\n",
    "    \n",
    "    # deal with over fitting\n",
    "      # Use small max_bin\n",
    "      # Use small num_leaves\n",
    "      # Use min_data_in_leaf and min_sum_hessian_in_leaf\n",
    "      # Use bagging by set bagging_fraction and bagging_freq\n",
    "      # Use feature sub-sampling by set feature_fraction\n",
    "      # Use bigger training data\n",
    "      # Try lambda_l1, lambda_l2 and min_gain_to_split for regularization\n",
    "      # Try max_depth to avoid growing deep tree\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \n",
    "    \"min_child_samples\": 100,\n",
    "    \n",
    "    # other\n",
    "    \"n_estimators\": 941,\n",
    "    \"verbosity\": -1,\n",
    "    \"n_jobs\":8,\n",
    "}\n",
    "```\n",
    "3.0011259148454195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
